{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11588755,"sourceType":"datasetVersion","datasetId":7266578}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install spacy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:12:48.882892Z","iopub.execute_input":"2025-05-09T07:12:48.883415Z","iopub.status.idle":"2025-05-09T07:12:53.693543Z","shell.execute_reply.started":"2025-05-09T07:12:48.883390Z","shell.execute_reply":"2025-05-09T07:12:53.692595Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# python -m spacy download en_core_web_sm\n\nimport subprocess\n\ntry:\n    subprocess.check_call(['python', '-m', 'spacy', 'download', 'en_core_web_sm'])\nexcept subprocess.CalledProcessError as e:\n    print(f\"Error downloading model: {e}\")\n    print(e.output) #Print the full error message. This is often more useful than just the exception.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:12:53.695030Z","iopub.execute_input":"2025-05-09T07:12:53.695379Z","iopub.status.idle":"2025-05-09T07:13:07.512289Z","shell.execute_reply.started":"2025-05-09T07:12:53.695332Z","shell.execute_reply":"2025-05-09T07:13:07.511679Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 91.2 MB/s eta 0:00:00\nRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## MedQuAD Dataset Sampling and Answer Cleaning","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom datasets import load_dataset\nimport pandas as pd\nimport json\nimport spacy\nfrom nltk.tokenize import sent_tokenize\nimport nltk\nimport random\n\n# Download NLTK sentence tokenizer (run this only for the first time)\nnltk.download('punkt')\n\n# Load Spacy model for natural language processing\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Load MedQuAD dataset\nmedquad_dataset = load_dataset(\"keivalya/MedQuad-MedicalQnADataset\")\nif 'train' in medquad_dataset:\n    medquad_df = medquad_dataset['train'].to_pandas()\n    print(\"Original dataset size:\", len(medquad_df))\nelse:\n    print(\"Error: 'train' section not found in the dataset\")\n    medquad_df = pd.DataFrame()\n\n# Set random seed for reproducibility\nrandom_seed = 42\nrandom.seed(random_seed)\n\n# Randomly sample 10000 examples\nsample_size = 10000\nif len(medquad_df) >= sample_size:\n    sampled_df = medquad_df.sample(n=sample_size, random_state=random_seed)\nelse:\n    sampled_df = medquad_df\nprint(\"Sampled dataset size:\", len(sampled_df))\n\n# Define cleaning function: extract sentences related to the question\ndef clean_sample(row):\n    question = row.get(\"Question\")\n    answer = row.get(\"Answer\")\n\n    # Check for null values\n    if not (question and answer):\n        return {\"Question\": question, \"Answer\": answer}\n\n    # Tokenize the answer into sentences\n    sentences = sent_tokenize(answer)\n\n    # Analyze the question using Spacy to extract keywords (nouns and verbs)\n    question_doc = nlp(question.lower())\n    question_keywords = [token.text for token in question_doc if token.pos_ in [\"NOUN\", \"VERB\"]]\n\n    # Extract relevant sentences\n    relevant_sentences = []\n    for sent in sentences:\n        sent_doc = nlp(sent.lower())\n        sent_tokens = [token.text for token in sent_doc]\n        # Keep the sentence if it contains question keywords\n        if any(keyword in sent_tokens for keyword in question_keywords):\n            relevant_sentences.append(sent)\n\n    # If no relevant sentences are found, keep the original answer\n    cleaned_answer = \" \".join(relevant_sentences) if relevant_sentences else answer\n    return {\"Question\": question, \"Answer\": cleaned_answer}\n\n# Apply the cleaning function to the sampled data\ncleaned_df = sampled_df.apply(clean_sample, axis=1, result_type='expand')\nprint(\"Cleaning complete, processed sample size:\", len(cleaned_df))\n\n# Save to .jsonl file\ndef save_to_jsonl(df, filename):\n    with open(filename, 'w', encoding='utf-8') as f:\n        for index, row in df.iterrows():\n            json.dump(row.to_dict(), f, ensure_ascii=False)\n            f.write('\\n')\n\nsave_to_jsonl(cleaned_df, \"medquad_sampled_cleaned.jsonl\")\nprint(\"Cleaned samples saved to medquad_sampled_cleaned.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:13:07.512976Z","iopub.execute_input":"2025-05-09T07:13:07.513188Z","iopub.status.idle":"2025-05-09T07:25:32.578074Z","shell.execute_reply.started":"2025-05-09T07:13:07.513171Z","shell.execute_reply":"2025-05-09T07:25:32.577453Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/233 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f442cea6ba584b64bbe139c4fa9490e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medDataset_processed.csv:   0%|          | 0.00/22.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b165b4df17439baa427b7eef8cd340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16407 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e8c10d9d634a35b1f6b0007f812fba"}},"metadata":{}},{"name":"stdout","text":"Original dataset size: 16407\nSampled dataset size: 10000\nCleaning complete, processed sample size: 10000\nCleaned samples saved to medquad_sampled_cleaned.jsonl\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Check for duplicates in the cleaned data\nduplicates = cleaned_df.duplicated(subset=[\"Question\", \"Answer\"])\nprint(\"Number of duplicate samples:\", duplicates.sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:27:15.851298Z","iopub.execute_input":"2025-05-09T07:27:15.851587Z","iopub.status.idle":"2025-05-09T07:27:15.876077Z","shell.execute_reply.started":"2025-05-09T07:27:15.851568Z","shell.execute_reply":"2025-05-09T07:27:15.875472Z"}},"outputs":[{"name":"stdout","text":"Number of duplicate samples: 23\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\n\n# knowledge_base_file = \"medquad_sampled.jsonl\"\nknowledge_base_file = \"medquad_sampled_cleaned.jsonl\"\n\nfirst_ten_entries = []\n\ntry:\n    with open(knowledge_base_file, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(f):\n            if i < 10:\n                data = json.loads(line)\n                first_ten_entries.append(data)\n            else:\n                break  # Stop after reading the first ten entries\n\n    if first_ten_entries:\n        print(\"First ten entries from the medquad_sampled.jsonl file:\")\n        for entry in first_ten_entries:\n            print(json.dumps(entry, ensure_ascii=False, indent=2))\n    else:\n        print(f\"The file {knowledge_base_file} is empty or contains fewer than ten entries.\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file {knowledge_base_file} was not found. Please ensure the file has been generated and is located in the current directory.\")\nexcept Exception as e:\n    print(f\"An error occurred while reading the file: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:27:15.877234Z","iopub.execute_input":"2025-05-09T07:27:15.877529Z","iopub.status.idle":"2025-05-09T07:27:15.884643Z","shell.execute_reply.started":"2025-05-09T07:27:15.877509Z","shell.execute_reply":"2025-05-09T07:27:15.883899Z"}},"outputs":[{"name":"stdout","text":"First ten entries from the medquad_sampled.jsonl file:\n{\n  \"Question\": \"What are the treatments for High Blood Pressure ?\",\n  \"Answer\": \"Today, many different types of medicines are available to control high blood pressure. Some lower blood pressure by removing extra fluid and salt from your body. Others affect blood pressure by slowing down the heartbeat, or by relaxing and widening blood vessels. Here are the types of medicines used to treat high blood pressure. -   Diuretics (water or fluid Pills)  flush excess sodium from your body, which reduces the amount of fluid in your blood and helps to lower your blood pressure. Diuretics are often used with other high blood pressure medicines, sometimes in one combined pill. As a result, your heart pumps less blood through your blood vessels, which can help to lower your blood pressure. Angiotensin-II is a hormone that narrows blood vessels, increasing blood pressure. ACE inhibitors block this process, which stops the production of Angiotensin II, lowering blood pressure. -  Angiotensin II Receptor Blockers (ARBs) block angiotensin II hormone from binding with receptors in the blood vessels. When angiotensin II is blocked, the blood vessels do not constrict or narrow, which can lower your blood pressure. -  Calcium Channel Blockers keep calcium from entering the muscle cells of your heart and blood vessels. This allows blood vessels to relax, which can lower your blood pressure. -  Alpha Blockers reduce nerve impulses that tighten blood vessels. This allows blood to flow more freely, causing blood pressure to go down. As a result, blood pressure goes down. -  Central Acting Agents act in the brain to decrease nerve signals that narrow blood vessels, which can lower blood pressure. -  Vasodilators relax the muscles in blood vessel walls, which can lower blood pressure. Diuretics (water or fluid Pills)  flush excess sodium from your body, which reduces the amount of fluid in your blood and helps to lower your blood pressure. Diuretics are often used with other high blood pressure medicines, sometimes in one combined pill. As a result, your heart pumps less blood through your blood vessels, which can help to lower your blood pressure. Angiotensin-II is a hormone that narrows blood vessels, increasing blood pressure. ACE inhibitors block this process, which stops the production of Angiotensin II, lowering blood pressure. Angiotensin II Receptor Blockers (ARBs) block angiotensin II hormone from binding with receptors in the blood vessels. When angiotensin II is blocked, the blood vessels do not constrict or narrow, which can lower your blood pressure. Calcium Channel Blockers keep calcium from entering the muscle cells of your heart and blood vessels. This allows blood vessels to relax, which can lower your blood pressure. Alpha Blockers reduce nerve impulses that tighten blood vessels. This allows blood to flow more freely, causing blood pressure to go down. As a result, blood pressure goes down. Central Acting Agents act in the brain to decrease nerve signals that narrow blood vessels, which can lower blood pressure. Vasodilators relax the muscles in blood vessel walls, which can lower blood pressure.\"\n}\n{\n  \"Question\": \"What are the treatments for 21-hydroxylase deficiency ?\",\n  \"Answer\": \"What is the goal for treating 21-hydroxylase-deficient congenital adrenal hyperplasia? The objectives for treating 21-hydroxylase deficiency differ with age. Also, it is important that teens and young adults with 21-hydroxylase deficiency be successfully transitioned to adult care facilities. Adult males may develop enlargement of the testes and if so, should work with an endocrinologist familiar with the management of patients with this deficiency.\"\n}\n{\n  \"Question\": \"How to diagnose Fanconi Anemia ?\",\n  \"Answer\": \"People who have Fanconi anemia (FA) are born with the disorder. The tests used to diagnose FA depend on a person's age and symptoms. They also can provide counseling about how FA is inherited and the types of prenatal (before birth) testing used to diagnose it. A hematologist (blood disease specialist) also may help diagnose FA. Knowing your family medical history can help your doctor diagnose whether you or your child has FA or another condition with similar symptoms. If your doctor thinks that you, your siblings, or your children have FA, he or she may ask you detailed questions about:\\n                \\nAny personal or family history of anemia\\n                \\nAny surgeries youve had related to the digestive system\\n                \\nAny personal or family history of immune disorders\\n                \\nYour appetite, eating habits, and any medicines you take\\n                \\nIf you know your family has a history of FA, or if your answers to your doctor's questions suggest a possible diagnosis of FA, your doctor will recommend further testing. They're also linked to many other diseases and conditions, such as aplastic anemia. Two tests can be used to diagnose FA in a developing fetus: amniocentesis (AM-ne-o-sen-TE-sis) and chorionic villus (ko-re-ON-ik VIL-us) sampling (CVS). For more information about these defects, go to What Are the Signs and Symptoms of Fanconi Anemia? Doctors may not diagnose them with the disorder until signs of bone marrow failure or cancer occur. If your bone marrow is failing, you may have signs of aplastic anemia. FA is one type of aplastic anemia. In aplastic anemia, your bone marrow stops making or doesn't make enough of all three types of blood cells: red blood cells, white blood cells, and platelets. Aplastic anemia can be inherited or acquired after birth through exposure to chemicals, radiation, or medicines. Doctors diagnose aplastic anemia using:\\n                \\nFamily and medical histories and a physical exam. If you or your child is diagnosed with aplastic anemia, your doctor will want to find the cause. For more information, go to the Health Topics Aplastic Anemia article.\"\n}\n{\n  \"Question\": \"How many people are affected by glutaric acidemia type I ?\",\n  \"Answer\": \"Glutaric acidemia type I occurs in approximately 1 of every 30,000 to 40,000 individuals. It is much more common in the Amish community and in the Ojibwa population of Canada, where up to 1 in 300 newborns may be affected.\"\n}\n{\n  \"Question\": \"how is hps diagnosed and treated for Hantavirus ?\",\n  \"Answer\": \"Diagnosing HPS\\n  \\nDiagnosing HPS in an individual who has only been infected a few days is difficult, because early symptoms such as fever, muscle aches, and fatigue are easily confused with influenza. However, if the individual is experiencing fever and fatigue and has a history of potential rural rodent exposure, together with shortness of breath, would be strongly suggestive of HPS. Treating HPS\\n  \\n    \\n      \\n     \\n   \\n  \\n  \\nThere is no specific treatment, cure, or vaccine for hantavirus infection. Be sure to tell your doctor that you have been around rodents—this will alert your physician to look closely for any rodent-carried disease, such as HPS.\"\n}\n{\n  \"Question\": \"What are the symptoms of Microscopic Colitis: Collagenous Colitis and Lymphocytic Colitis ?\",\n  \"Answer\": \"The most common symptom of microscopic colitis is chronic, watery, nonbloody diarrhea. However, many people with microscopic colitis may have long periods without diarrhea. Other signs and symptoms of microscopic colitis can include\\n                \\n- a strong urgency to have a bowel movement or a need to go to the bathroom quickly  - pain, cramping, or bloating in the abdomenthe area between the chest and the hipsthat is usually mild  - weight loss  - fecal incontinenceaccidental passing of stool or fluid from the rectumespecially at night  - nausea  - dehydrationa condition that results from not taking in enough liquids to replace fluids lost through diarrhea\\n                \\nThe symptoms of microscopic colitis can come and go frequently. Sometimes, the symptoms go away without treatment.\"\n}\n{\n  \"Question\": \"Is surfactant dysfunction inherited ?\",\n  \"Answer\": \"Surfactant dysfunction can have different inheritance patterns depending on its genetic cause. When caused by mutations in the SFTPB or ABCA3 gene, this condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations.\"\n}\n{\n  \"Question\": \"Is complement component 2 deficiency inherited ?\",\n  \"Answer\": \"This condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations.\"\n}\n{\n  \"Question\": \"What are the symptoms of Charcot-Marie-Tooth disease type 2O ?\",\n  \"Answer\": \"What are the signs and symptoms of Charcot-Marie-Tooth disease type 2O? The Human Phenotype Ontology provides the following list of signs and symptoms for Charcot-Marie-Tooth disease type 2O. Signs and Symptoms Approximate number of patients (when available) Autosomal dominant inheritance - Decreased motor nerve conduction velocity - Difficulty running - Distal muscle weakness - Distal sensory impairment - Frequent falls - Hyporeflexia - Limb muscle weakness - Motor delay - Pes cavus - Phenotypic variability - Slow progression - The Human Phenotype Ontology (HPO) has collected information on how often a sign or symptom occurs in a condition. Much of this information comes from Orphanet, a European rare disease database.\"\n}\n{\n  \"Question\": \"What is (are) 3MC syndrome ?\",\n  \"Answer\": \"3MC syndrome is a disorder characterized by unusual facial features and problems affecting other tissues and organs of the body. The distinctive facial features of people with 3MC syndrome include widely spaced eyes (hypertelorism), a narrowing of the eye opening (blepharophimosis), droopy eyelids (ptosis), highly arched eyebrows, and an opening in the upper lip (cleft lip) with an opening in the roof of the mouth (cleft palate). Other features of 3MC syndrome can include abnormal fusion of certain bones in the skull (craniosynostosis) or forearm (radioulnar synostosis); an outgrowth of the tailbone (caudal appendage); a soft out-pouching around the belly-button (an umbilical hernia); and abnormalities of the kidneys, bladder, or genitals. 3MC syndrome encompasses four disorders that were formerly considered to be separate: Mingarelli, Malpeuch, Michels, and Carnevale syndromes.\"\n}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## RAG with Cross-Encoder Reranking for Question Answering","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y transformers\n!pip install -q transformers\n!pip install -q --upgrade sentence-transformers\n!pip install -q faiss-cpu\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\nfrom sentence_transformers import SentenceTransformer, util\nimport faiss\nimport torch\nimport numpy as np\nimport json\n\n# Load model\nprint(\"Loading models...\")\nretriever = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\") \n\ncross_encoder = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\ncross_tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n\nqa_tokenizer = AutoTokenizer.from_pretrained(\"Nin8520/MedQA_v2\")\nqa_model = AutoModelForSeq2SeqLM.from_pretrained(\"Nin8520/MedQA_v2\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nqa_model.to(device)\ncross_encoder.to(device)\n\n# Load knowledge base from .jsonl file and build FAISS index\nknowledge_base_file = \"/kaggle/working/medquad_sampled_cleaned.jsonl\"\nknowledge_base = []\ntry:\n    with open(knowledge_base_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            data = json.loads(line)\n            knowledge_base.append(data[\"Answer\"]) \n        print(f\"Successfully loaded {len(knowledge_base)} knowledge base documents.\")\nexcept FileNotFoundError:\n    print(f\"Error: Could not find knowledge base file {knowledge_base_file}. Please ensure the file has been generated and is in the current directory.\")\n    knowledge_base = []\n\nif knowledge_base:\n    print(\"Building FAISS index...\")\n    # Encode the knowledge base documents into embeddings\n    document_embeddings = retriever.encode(knowledge_base, convert_to_numpy=True) \n    # Get the dimensionality of the embeddings\n    dimension = document_embeddings.shape[1] \n    # Create a Flat L2 FAISS index with the embedding dimension\n    index = faiss.IndexFlatL2(dimension) \n    # Add the document embeddings to the FAISS index\n    index.add(document_embeddings) \nelse:\n    index = None\n    print(\"Knowledge base is empty, cannot build FAISS index.\")\n\n# Retrieve + rerank\ndef retrieve_and_rerank(question, top_k=3):\n    if index is None:\n        return []\n    # Encode the input question into a vector embedding\n    question_embedding = retriever.encode(question, convert_to_numpy=True) \n    # Search the FAISS index for the top_k most similar document embeddings\n    D, I = index.search(np.array([question_embedding]), top_k) \n    # Retrieve the actual text passages corresponding to the top_k indices\n    retrieved_passages = [knowledge_base[i] for i in I[0]] \n\n    # Create pairs of (question, retrieved passage) for cross-encoder input\n    cross_inputs = [(question, passage) for passage in retrieved_passages] \n    # Tokenize and encode the question-passage pairs for the cross-encoder\n    encoded = cross_tokenizer.batch_encode_plus(cross_inputs, padding=True, truncation=True, return_tensors=\"pt\").to(device) \n    with torch.no_grad():\n        # Get the relevance scores from the cross-encoder for each question-passage pair\n        scores = cross_encoder(**encoded).logits.squeeze(-1) \n\n    # Get the indices that would sort the scores in descending order\n    sorted_indices = torch.argsort(scores, descending=True) \n    # Reorder the retrieved passages based on the cross-encoder scores\n    reranked_passages = [retrieved_passages[i] for i in sorted_indices] \n\n    return reranked_passages\n\n# QA Answer Generation\ndef answer_question_rerank(question):\n    # Retrieve and rerank the passages based on the question, limiting the number of retrieved documents\n    retrieved_passages = retrieve_and_rerank(question, top_k=3) \n    context = \"\\n\".join(retrieved_passages)\n\n    prompt = f\"Question: {question}\\nContext: {context}\\nAnswer (Briefly summarize and keep it concise):\"\n\n    # Tokenize the prompt with truncation to a maximum length\n    inputs = qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n\n    # Generate the answer with more focused generation settings\n    with torch.no_grad():\n        output = qa_model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=1024,  # Limit the maximum length of generated text\n            num_beams=7,  # Increased beams for better quality\n            do_sample=False,  # Disable sampling to ensure controlled generation\n            top_p=0.95,\n            temperature=0.7,  # Lower temperature to ensure concise answers\n            no_repeat_ngram_size=3,\n            repetition_penalty=1.2,\n            # max_new_tokens=250,  # Limit the number of new tokens to avoid overly long answers\n            eos_token_id=qa_tokenizer.eos_token_id,  # Force the model to stop generating when it encounters the eos token\n        )\n\n    # Decode the generated answer and return\n    answer = qa_tokenizer.decode(output[0], skip_special_tokens=True)\n    return answer\n\n# Test\nif __name__ == \"__main__\":\n    user_question = \"Is surfactant dysfunction inherited ?\"\n    final_answer = answer_question_rerank(user_question)\n    print(f\"Q: {user_question}\")\n    print(f\"A: {final_answer}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:27:15.885413Z","iopub.execute_input":"2025-05-09T07:27:15.885938Z","iopub.status.idle":"2025-05-09T07:30:09.271863Z","shell.execute_reply.started":"2025-05-09T07:27:15.885909Z","shell.execute_reply":"2025-05-09T07:30:09.271053Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.51.1\nUninstalling transformers-4.51.1:\n  Successfully uninstalled transformers-4.51.1\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"2025-05-09 07:28:55.792756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746775736.038540      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746775736.104870      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading models...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7091a108c941599302f81cb8b6a85f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd56fa8bae8a46e6a4c1db0482292d20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d5ce48450644f0998756ed45c0287f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88038b03936420fa75dbd28562b92d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63198a9049a44162a5d948940bf20a76"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa74f8f7c8f4a8cb7e2db837f3b7354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47b02d3895a4385b565663d75a5b892"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a17e15f14b432ab64bbdfcbddaea76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cec49c37a3438da60832742f81972c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69ebefff3afc4a40921796de8c9b7c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1550b9b71f49feada78898bb24e9c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996f35ef6411483ea3a20c52f277d716"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f484c69306c445bf8c9f828cec7b2040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29845a9a7fef4c629744fabd65474589"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cceb13b459241c0b1daca0c6dc772e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b4b2ea58b84a4cb75edfae7c0e2649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76492d844c9747f9b3a566e05b0a858a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53326be430c49a49b14fc72e13151c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4370ebcbea404b0e9fa59d6a9852b626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7f7afe37984294b93c2cc43b71b866"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1b62fa35bb4f41a6d890db66ea69a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/851 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"278dfc0bed1a4cd1b77c51b777448904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa787245615043c1bcbbd66e10388917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d9796f945b4f6cb98f9b46fd7a0e3d"}},"metadata":{}},{"name":"stdout","text":"Successfully loaded 10000 knowledge base documents.\nBuilding FAISS index...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15cee254eb4b48e7a08ee676950d03ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f0433e4c9a4a209ff17cc5c403954b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Q: Is surfactant dysfunction inherited ?\nA: Answer (Briefly summarize and keep it concise): Surfactant dysfunction is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. This condition results from abnormalities in the composition or function of surfactant, a mixture of certain fats (called phospholipids) and proteins that lines the lung tissue and makes breathing easy. When caused by mutations in the SFTPB or ABCA3 gene, this condition is characterized by signs and symptoms that range from mild to severe. In some cases, the cause of the condition is unknown. In others, the condition may be caused by a mutation in one or more of the following genes: SP-C deficiency, ABCA3, or SP-B. The cause of these mutations is unknown; however, it is thought to be related to a genetic cause. Some people with this condition have no history of the disorder in their family, while others have a history of a condition that has been described as a rare condition. In these cases, no information on the cause is available. Researchers believe that a combination of genetic and environmental factors may cause the condition. However, researchers do not know how these factors contribute to the development of this condition. Researchers suspect that the genetic cause of this disorder may be unknown. Researchers also believe that other factors may play a role in causing the condition, such as genetic factors, environmental factors, or environmental factors that affect the body's ability to make certain substances (such as fats, proteins, and hormones). Other factors may also play an important role in the development and progression of the disease. These factors include the following: - The presence or absence of certain proteins in the lungs (the alveoli); - An abnormal amount of fat in the air sacs; - A lack of protein in the blood (the pulmonary arteries); and - a lack of oxygen (the oxygen-rich part of the blood). - Lack of oxygen in the brain (the brain's main organ) and the heart (the heart's pumping organ). This condition can also occur in other parts of the body, including the liver, kidneys, and lungs. - Genetic factors that increase the risk of developing this condition include obesity, diabetes, high blood pressure, and high blood cholesterol. In addition to these factors, there are other factors that can increase the chance of developing the disorder. The most common risk factors for this condition are smoking, obesity, and low blood pressure (hypothyroidism). The prevalence of these conditions is unknown, although it is estimated to occur in 1 in 1 million newborns worldwide. Other factors that may increase the likelihood of developing these conditions include smoking, eating a diet that is high in fats and proteins, being overweight or obese, having a family history of diabetes, and having an increased risk of heart disease. There are several factors that influence the development or progression of these disorders, including age, gender, family history, and genetic factors. In most cases, these factors are unknown. Most people with the condition do not have any signs or symptoms, but they may have difficulty breathing or breathing problems. The severity of the symptoms can vary in severity. The Human Phenotype Ontology (HPO) has collected information on how often an affected person has a sign or symptom. Much of this information comes from Orphanet, an European rare disease database. The frequency of an occurrence is usually listed as an estimate of the percentage of patients who have that feature, and the fractions may also be listed as fractions. The first number of the fraction is how many people had the symptom, and second number is the total number of people who were examined in one study. For example, if a frequency of 25/25 means that in a study of 25 people all patients were found to have that symptom (because they were all examined), the percentages may be different if another group of patients are examined. Because these frequencies are based on a specific study, fractions cannot be used to estimate the prevalence of an individual condition. Sometimes, the frequency may be higher or lower than the frequency of the same symptom in another study. If the frequency is higher, the result may be that the person has more than one symptom at a time. People with a higher frequency may have fewer than 1 symptom per study. In people with an increased frequency, the number of patients may be less than 1 in 1,000. The number of individuals who have an increased number of symptom may be greater than or equal to that of the person who had the lower frequency. This means that if the person had a lower frequency, he or she may have more than 2 Symptoms per study, but not all patients are affected. Because the frequency\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## RAG with Enhanced Prompt Engineering for Question Answering","metadata":{}},{"cell_type":"code","source":"# Install dependencies\n!pip uninstall -y transformers\n!pip install -q transformers\n!pip install -q --upgrade sentence-transformers\n!pip install -q faiss-cpu\n\n# Import libraries\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom sentence_transformers import SentenceTransformer\nimport faiss\nimport torch\nimport numpy as np\nimport json\n\n# Load models (only load retriever and QA model)\nprint(\"Loading models...\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nretriever = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")  # Retriever\nqa_tokenizer = AutoTokenizer.from_pretrained(\"Nin8520/MedQA_v2\")\nqa_model = AutoModelForSeq2SeqLM.from_pretrained(\"Nin8520/MedQA_v2\").to(device)\n\n\n\n# Load knowledge base from .jsonl file and build FAISS index (keep unchanged)\nknowledge_base_file = \"/kaggle/working/medquad_sampled_cleaned.jsonl\"\nknowledge_base = []\ntry:\n    with open(knowledge_base_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            data = json.loads(line)\n            knowledge_base.append(data[\"Answer\"])  # Use \"Answer\" as knowledge base documents\n    print(f\"Successfully loaded {len(knowledge_base)} knowledge base documents.\")\nexcept FileNotFoundError:\n    print(f\"Error: Knowledge base file {knowledge_base_file} not found. Please ensure the file has been generated and is located in the current directory.\")\n    knowledge_base = []\n\nif knowledge_base:\n    print(\"Building FAISS index...\")\n    document_embeddings = retriever.encode(knowledge_base, convert_to_numpy=True)\n    dimension = document_embeddings.shape[1]\n    index = faiss.IndexFlatL2(dimension)\n    index.add(document_embeddings)\nelse:\n    index = None\n    print(\"Knowledge base is empty, unable to build FAISS index.\")\n\n# Retrieval (without using rerank)\ndef retrieve_documents(question, top_k=3):\n    if index is None:\n        return []\n    question_embedding = retriever.encode(question, convert_to_numpy=True)\n    D, I = index.search(np.array([question_embedding]), top_k)\n    retrieved_passages = [knowledge_base[i] for i in I[0]]\n    return retrieved_passages\n\n# QA Generates the answer (using Prompt Engineering)\ndef answer_question_prompt(question):\n    retrieved_passages = retrieve_documents(question, top_k=3)\n    context = \"\\n\".join(retrieved_passages)\n\n    # # Enhance Prompt Engineering: Guide the model to summarize and respond more explicitly\n    prompt = f\"\"\"Answer the following question based on the provided context.\n                        Maintain conciseness and answer the core points.\n                        If the context does not contain the answer, state that the answer is not available in the provided context.\n\nQuestion: {question}\n\nContext:\n{context}\n\nAnswer: \"\"\"\n\n    inputs = qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n    with torch.no_grad():\n        output = qa_model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=512, \n            num_beams=5,      \n            do_sample=False, # Keep generation deterministic\n            top_p=0.95,\n            temperature=0.7,\n            no_repeat_ngram_size=3,\n            repetition_penalty=1.1,\n            eos_token_id=qa_tokenizer.eos_token_id,\n        )\n    answer = qa_tokenizer.decode(output[0], skip_special_tokens=True)\n    return answer\n\n# Test \nif __name__ == \"__main__\":\n    user_question = \"Is surfactant dysfunction inherited ?\"\n    final_answer = answer_question_prompt(user_question)\n    print(f\"Q: {user_question}\")\n    print(f\"A: {final_answer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:30:09.273708Z","iopub.execute_input":"2025-05-09T07:30:09.274032Z","iopub.status.idle":"2025-05-09T07:30:53.923577Z","shell.execute_reply.started":"2025-05-09T07:30:09.274000Z","shell.execute_reply":"2025-05-09T07:30:53.922885Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Found existing installation: transformers 4.51.3\nUninstalling transformers-4.51.3:\n  Successfully uninstalled transformers-4.51.3\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Loading models...\nSuccessfully loaded 10000 knowledge base documents.\nBuilding FAISS index...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbc8f9be29044423b1145aefac3341fc"}},"metadata":{}},{"name":"stdout","text":"Q: Is surfactant dysfunction inherited ?\nA: Answer: Surfactant dysfunction is a lung disorder that causes breathing problems. This condition results from abnormalities in the composition or function of surfactant, a mixture of certain fats (called phospholipids) and proteins that lines the lung tissue and makes breathing easy. Other types, known as SP-C dysfunction and ABCA3 deficiency, have signs and symptoms that range from mild to severe.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Without RAG model output (for comparison)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Nin8520/MedQA_v2\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Nin8520/MedQA_v2\")\n\n# Set the model to evaluation mode and move to the appropriate device (GPU/CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\ndef generate_answer_original(question: str, tokenizer, model, device):\n    \"\"\"Generate an answer for a given question using the pre-trained model.\"\"\"\n    # Tokenize the input question\n    inputs = tokenizer(\n        f\"Question: {question}\",\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128  # You can adjust this as needed\n    )\n\n    # Move input tensors to the correct device\n    input_ids = inputs[\"input_ids\"].to(device)\n    attention_mask = inputs[\"attention_mask\"].to(device)\n\n    # Generate an answer using the model\n    with torch.no_grad():\n        generated_ids = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=1024,  # Adjust the max output length\n            num_beams=5,  # Number of beams for beam search\n            length_penalty=1.2,\n            no_repeat_ngram_size=3,\n            repetition_penalty=1.2,\n            top_k=50,\n            do_sample=True,\n            early_stopping=True\n        )\n\n    # Decode the generated answer\n    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return answer\n\n# Example usage\nif __name__ == \"__main__\":\n    question = \"Is surfactant dysfunction inherited ?\"\n    answer = generate_answer_original(question, tokenizer, model, device)\n    print(f\"Q: {question}\")\n    print(f\"A: {answer}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:30:53.924430Z","iopub.execute_input":"2025-05-09T07:30:53.924696Z","iopub.status.idle":"2025-05-09T07:31:20.294445Z","shell.execute_reply.started":"2025-05-09T07:30:53.924668Z","shell.execute_reply":"2025-05-09T07:31:20.293675Z"}},"outputs":[{"name":"stdout","text":"Q: Is surfactant dysfunction inherited ?\nA: Answer: Surfactant dysfunction is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. In some cases, the parents of an individual with this condition each carry one copy of the mutated gene, but they typically do not show signs and symptoms of the condition. mes Itstler gland glands to produce a hormone called surfactant (surfactant) phosphorylation, which is a protein that attaches to the surface of the skin and protects the skin from damage caused by contact with other parts of the body, such as the skin, hair, eyes, ears, and nails. Information about the prevalence of this condition is available from the National Institute of Neurological Disorders and Strokeizes the underlying genetic cause of the disorder, which may be inherited as a result of a mutation in the CYP1A gene.ia may occur in people with no history of this disorder in their family, or it may be caused by mutations in one or more of the following genes: - A chromosome containing at least one X-linked gene. This gene provides instructions for making an enzyme called sulfate reductase. It is unknown whether this enzyme is involved in the formation of surfactants, but it has been suggested that it may play a role in the development of many other health conditions, including heart disease, diabetes, high blood pressure, kidney disease, and a variety of other health problems.ant dysfunction may also be associated with a higher risk of developing a congenital malformation of the parathyroid gland, which leads to a decrease in the amount of phosphorus in the blood.: This condition is characterized by a lack of calcium in the cerebrospinal fluid (CSF), which is found in the bones of the brain and spinal cord, and is present in approximately half of all affected individuals. deficiency is usually caused by an inherited mutation in one of the two genes that control the production of sperm cells, and the other gene is responsible for regulating the rate of growth of certain genes in the body., there is no specific sign or symptom associated with this disorder, but a number of features are associated with the condition, including short stature (hypotonia), a low level of bone marrow acidosis, a rapid decline in bone mineral density, and an increased risk of bone fractures, particularly in the hips and knees, which can lead to osteoporosis (a condition in which a person's bone density is lower than normal, leading to abnormal bone morphology and abnormality of the bone skeleton, resulting in a loss of bone density in the hands and feet; however, this condition can also occur in other organs and tissues, including the brain, heart, liver, kidneys, and pancreas.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Test: Generate RAG answers for the dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 读取 CSV 文件，生成答案并写入 (在新的代码块中执行)\ninput_csv_path = \"/kaggle/input/evaluate/bioasq2_dataset.csv\" \noutput_csv_path = \"/kaggle/working/bioasq2_dataset_rag_prompt.csv\"\n\ntry:\n    df = pd.read_csv(input_csv_path)\n    # 确保 CSV 文件中有列叫 \"Question\"\n    if \"Question\" not in df.columns:\n        print(\"错误：CSV 文件中必须有 'Question' 列！\")\n    else:\n        df[\"RAG Response\"] = \"\"\n        for idx, row in df.iterrows():\n            question = row[\"Question\"]\n            rag_response = answer_question(question)  \n            df.at[idx, \"RAG Response\"] = rag_response\n\n        df.to_csv(output_csv_path, index=False)\n        print(f\"处理完毕！生成的文件保存到：{output_csv_path}\")\n\nexcept FileNotFoundError:\n    print(f\"错误：找不到输入 CSV 文件：{input_csv_path}\")\nexcept Exception as e:\n    print(f\"处理 CSV 文件时发生错误：{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:31:20.295315Z","iopub.execute_input":"2025-05-09T07:31:20.295600Z","iopub.status.idle":"2025-05-09T07:31:20.299673Z","shell.execute_reply.started":"2025-05-09T07:31:20.295573Z","shell.execute_reply":"2025-05-09T07:31:20.298837Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Download ","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\nimport pandas as pd\n\n# 检查文件是否存在\nfile_path = '/kaggle/working/bioasq2_dataset_rag_prompt.csv'\nif os.path.exists(file_path):\n    print(\"文件已生成，准备下载...\")\n    \n    # 方法1：直接生成下载链接（适用于 Kaggle Notebook）\n    display(FileLink(file_path, result_html_prefix=\"点击下载: \"))\n    \n    # 方法2：保存为 Pandas DataFrame 并下载（验证数据完整性）\n    df = pd.read_csv(file_path)\n    output_path = 'bioasq2_dataset_rag_prompt_download.csv'\n    df.to_csv(output_path, index=False)\n    display(FileLink(output_path))\nelse:\n    print(\"错误：文件未找到！请检查路径或文件是否生成成功。\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T07:31:20.300419Z","iopub.execute_input":"2025-05-09T07:31:20.300715Z","iopub.status.idle":"2025-05-09T07:31:20.318908Z","shell.execute_reply.started":"2025-05-09T07:31:20.300695Z","shell.execute_reply":"2025-05-09T07:31:20.318309Z"}},"outputs":[],"execution_count":12}]}